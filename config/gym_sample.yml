epoch: 100
steps_per_epoch: 1000

policy:
  obs_dim: 3
  act_dim: 1
  policy_hz: None

train:
  explore_steps: 4000
  update_after: 1000
  replay_size: 30000
  batch_size: 32

SAC:
  gamma: 0.99
  polyak: 0.005
  lr: 0.001
  alpha: 0.2

save_freqency: 5
